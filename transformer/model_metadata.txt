Model name: model_seen92K
  Num Parameters: 101,120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 92,160

Total batch size: 3,072

Max steps: 30

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: model_seen921K
  Num Parameters: 101,120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 921,600

Total batch size: 3,072

Max steps: 300

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: model_seen92M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 92,160,000

Total batch size: 3,072

Max steps: 30,000

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: model_seen921M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 921600000

Total batch size: 3,072

Max steps: 300,000

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_seen9M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9216000

Total batch size: 6,144

Max steps: 1,500

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_seen9M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9216000

Total batch size: 6,144

Max steps: 1,500

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_seen9M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9216000

Total batch size: 6,144

Max steps: 1,500

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_seen92M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 92160000

Total batch size: 6,144

Max steps: 15,000

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_1_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_1_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_2_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_3_seen9M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_1_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_2_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_3_seen9M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_6_seen1M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 1099776

Total batch size: 6,144

Max steps: 179

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_7_seen995K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_8_seen9M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_11_seen98K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_4_seen99M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_12_seen995K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_13_seen9M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_4_seen99M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_9_seen99M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_16_seen98K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_17_seen995K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_18_seen9M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_14_seen99M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_19_seen99M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_21_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_22_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_23_seen9M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_24_seen99M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_5_seen999M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_26_seen98K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_27_seen995K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_10_seen999M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_28_seen9M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_15_seen999M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_31_seen98K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_32_seen995K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_29_seen99M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_33_seen9M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_34_seen99M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_36_seen98K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_37_seen995K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_38_seen9M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_39_seen99M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_25_seen999M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_41_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_42_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_20_seen999M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_43_seen9M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_1_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_12_seen995K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_2_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_7_seen995K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_6_seen1M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 1099776

Total batch size: 6,144

Max steps: 179

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_11_seen98K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_8_seen9M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_3_seen9M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_16_seen98K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_17_seen995K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_13_seen9M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_21_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_22_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_18_seen9M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_26_seen98K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_23_seen9M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_27_seen995K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_28_seen9M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_9_seen99M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_4_seen99M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_14_seen99M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_32_seen995K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_33_seen9M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_24_seen99M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_19_seen99M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_36_seen98K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_37_seen995K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_29_seen99M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_41_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_42_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_43_seen9M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_34_seen99M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_46_seen98K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_47_seen995K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_48_seen9M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_39_seen99M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_44_seen99M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_51_seen98K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_52_seen995K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_53_seen9M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_49_seen99M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_54_seen99M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_57_seen995K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_58_seen9M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_5_seen999M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_61_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_10_seen999M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_62_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_15_seen999M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_25_seen999M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_66_seen98K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_67_seen995K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_68_seen9M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_30_seen999M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_71_seen98K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_72_seen995K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_64_seen99M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_35_seen999M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_76_seen98K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_77_seen995K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_74_seen99M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_81_seen98K
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_45_seen999M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_83_seen9M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_79_seen99M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_86_seen98K
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_87_seen995K
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_88_seen9M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_50_seen999M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_20_seen999M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_55_seen999M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_91_seen98K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_92_seen995K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_93_seen9M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_84_seen99M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_96_seen98K
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_97_seen995K
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_89_seen99M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_98_seen9M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_40_seen999M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_94_seen99M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_102_seen995K
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_103_seen9M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_60_seen999M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_106_seen98K
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_108_seen9M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_104_seen99M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_99_seen99M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_111_seen98K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_112_seen995K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_113_seen9M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_109_seen99M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_116_seen98K
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_114_seen99M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_118_seen9M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_65_seen999M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_70_seen999M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_121_seen98K
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_122_seen995K
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_123_seen9M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_75_seen999M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_119_seen99M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_126_seen98K
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_127_seen995K
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_128_seen9M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_124_seen99M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_80_seen999M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_131_seen98K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_132_seen995K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_129_seen99M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_136_seen98K
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_137_seen995K
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_138_seen9M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_134_seen99M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_139_seen99M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_141_seen98K
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_142_seen995K
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_143_seen9M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_85_seen999M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_144_seen99M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_146_seen98K
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_147_seen995K
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_148_seen9M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_95_seen999M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_90_seen999M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_151_seen98K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_152_seen995K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_153_seen9M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_149_seen99M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_110_seen999M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_156_seen98K
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_157_seen995K
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_154_seen99M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_158_seen9M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_115_seen999M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_161_seen98K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_159_seen99M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_162_seen995K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_163_seen9M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_164_seen99M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_166_seen98K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_167_seen995K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_130_seen999M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_125_seen999M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_168_seen9M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_171_seen98K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_172_seen995K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_173_seen9M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_100_seen999M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_135_seen999M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_176_seen98K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_177_seen995K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_178_seen9M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_169_seen99M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_140_seen999M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_174_seen99M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_181_seen98K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_182_seen995K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_183_seen9M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_120_seen999M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_186_seen98K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_184_seen99M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_187_seen995K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_188_seen9M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_150_seen999M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_179_seen99M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_191_seen98K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_192_seen995K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_145_seen999M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_193_seen9M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_196_seen98K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_197_seen995K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_198_seen9M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_155_seen999M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_189_seen99M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_201_seen98K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_202_seen995K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_203_seen9M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_194_seen99M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_160_seen999M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_204_seen99M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_206_seen98K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_207_seen995K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_199_seen99M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_208_seen9M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_211_seen98K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_212_seen995K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_213_seen9M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_209_seen99M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_214_seen99M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_216_seen98K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_217_seen995K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_218_seen9M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_219_seen99M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_165_seen999M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_221_seen98K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_222_seen995K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_223_seen9M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_170_seen999M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_224_seen99M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_226_seen98K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_227_seen995K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_228_seen9M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_175_seen999M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_229_seen99M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_231_seen98K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_232_seen995K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_185_seen999M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_233_seen9M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_234_seen99M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_236_seen98K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_237_seen995K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_190_seen999M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_238_seen9M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_195_seen999M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_241_seen98K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_242_seen995K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_243_seen9M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_239_seen99M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_205_seen999M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_246_seen98K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_247_seen995K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_248_seen9M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_244_seen99M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_210_seen999M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_251_seen98K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_252_seen995K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_253_seen9M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_215_seen999M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_249_seen99M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_256_seen98K
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_257_seen995K
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_258_seen9M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_254_seen99M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_180_seen999M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_261_seen98K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_262_seen995K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_263_seen9M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_220_seen999M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_200_seen999M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_266_seen98K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_230_seen999M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_267_seen995K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_225_seen999M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_268_seen9M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_271_seen98K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_272_seen995K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_264_seen99M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_273_seen9M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_259_seen99M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_276_seen98K
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_277_seen995K
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_235_seen999M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_278_seen9M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_269_seen99M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_281_seen98K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_282_seen995K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_283_seen9M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_274_seen99M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_240_seen999M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_286_seen98K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_284_seen99M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_287_seen995K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_288_seen9M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_279_seen99M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_291_seen98K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_292_seen995K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_293_seen9M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_289_seen99M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_294_seen99M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_297_seen995K
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_298_seen9M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_299_seen99M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_245_seen999M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_301_seen98K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_302_seen995K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_303_seen9M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_250_seen999M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_304_seen99M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_306_seen98K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_307_seen995K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_308_seen9M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_255_seen999M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_309_seen99M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_311_seen98K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_312_seen995K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_313_seen9M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_265_seen999M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_270_seen999M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_316_seen98K
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_317_seen995K
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_314_seen99M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_318_seen9M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_275_seen999M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_321_seen98K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_322_seen995K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_323_seen9M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_324_seen99M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_319_seen99M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_326_seen98K
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_327_seen995K
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_328_seen9M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_329_seen99M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_285_seen999M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_331_seen98K
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_332_seen995K
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_290_seen999M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_333_seen9M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_325_seen999M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_336_seen98K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_337_seen995K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_338_seen9M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_334_seen99M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_339_seen99M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_341_seen98K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_342_seen995K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_343_seen9M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_344_seen99M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_295_seen999M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_346_seen98K
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_347_seen995K
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_330_seen999M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_348_seen9M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_349_seen99M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_351_seen98K
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_352_seen995K
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_353_seen9M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_354_seen99M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_335_seen999M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_356_seen98K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_357_seen995K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_358_seen9M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_359_seen99M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_340_seen999M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_345_seen999M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_361_seen98K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_362_seen995K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_363_seen9M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_364_seen99M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_366_seen98K
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_367_seen995K
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_368_seen9M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_350_seen999M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_369_seen99M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_372_seen995K
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_373_seen9M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_355_seen999M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_374_seen99M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_376_seen98K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_377_seen995K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_378_seen9M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_379_seen99M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_365_seen999M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_381_seen98K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_382_seen995K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_383_seen9M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_360_seen999M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_260_seen999M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_370_seen999M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_384_seen99M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_387_seen995K
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_388_seen9M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_391_seen98K
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_392_seen995K
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_393_seen9M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_389_seen99M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_396_seen98K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_397_seen995K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_398_seen9M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_375_seen999M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_399_seen99M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_401_seen98K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_402_seen995K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_403_seen9M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_380_seen999M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_404_seen99M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_406_seen98K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_407_seen995K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_408_seen9M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_300_seen999M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_409_seen99M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_411_seen98K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_412_seen995K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_310_seen999M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_385_seen999M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_390_seen999M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_416_seen98K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_417_seen995K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_418_seen9M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_414_seen99M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_280_seen999M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_421_seen98K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_422_seen995K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_395_seen999M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_423_seen9M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_426_seen98K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_427_seen995K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_428_seen9M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_424_seen99M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_419_seen99M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_431_seen98K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_432_seen995K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_429_seen99M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_433_seen9M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_400_seen999M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_436_seen98K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_437_seen995K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_438_seen9M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_434_seen99M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_315_seen999M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_441_seen98K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_439_seen99M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_442_seen995K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_443_seen9M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_444_seen99M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_446_seen98K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_405_seen999M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_447_seen995K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_448_seen9M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_449_seen99M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_451_seen98K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_452_seen995K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_453_seen9M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_305_seen999M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_415_seen999M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_454_seen99M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_456_seen98K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_457_seen995K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_458_seen9M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_425_seen999M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_459_seen99M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_461_seen98K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_462_seen995K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_463_seen9M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_410_seen999M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_466_seen98K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_467_seen995K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_468_seen9M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_430_seen999M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_471_seen98K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_469_seen99M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_472_seen995K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_435_seen999M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_473_seen9M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_476_seen98K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_477_seen995K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_478_seen9M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_474_seen99M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_479_seen99M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_481_seen98K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_482_seen995K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_483_seen9M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_445_seen999M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_320_seen999M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_486_seen98K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_487_seen995K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_420_seen999M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_488_seen9M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_450_seen999M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_484_seen99M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_491_seen98K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_492_seen995K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_493_seen9M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_489_seen99M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_496_seen98K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_497_seen995K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_494_seen99M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_498_seen9M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_440_seen999M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_501_seen98K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_502_seen995K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_503_seen9M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_460_seen999M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_455_seen999M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_506_seen98K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_507_seen995K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_508_seen9M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_470_seen999M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_465_seen999M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_511_seen98K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_504_seen99M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_512_seen995K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_499_seen99M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_513_seen9M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_516_seen98K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_517_seen995K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_475_seen999M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_518_seen9M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_509_seen99M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_514_seen99M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_521_seen98K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_522_seen995K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_523_seen9M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_480_seen999M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_526_seen98K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_527_seen995K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_528_seen9M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_519_seen99M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_524_seen99M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_531_seen98K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_532_seen995K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_533_seen9M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_529_seen99M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_534_seen99M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_536_seen98K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_537_seen995K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_538_seen9M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_539_seen99M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_485_seen999M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_541_seen98K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_542_seen995K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_543_seen9M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_490_seen999M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_495_seen999M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_546_seen98K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_547_seen995K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_548_seen9M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_544_seen99M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_549_seen99M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_551_seen98K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_552_seen995K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_553_seen9M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_505_seen999M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_554_seen99M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_510_seen999M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_515_seen999M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_556_seen98K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_557_seen995K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_558_seen9M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_561_seen98K
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_562_seen995K
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_563_seen9M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_559_seen99M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_525_seen999M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_566_seen98K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_567_seen995K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_530_seen999M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_568_seen9M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_564_seen99M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_571_seen98K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_572_seen995K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_573_seen9M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_535_seen999M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_569_seen99M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_576_seen98K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_577_seen995K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_578_seen9M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_574_seen99M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_500_seen999M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_581_seen98K
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_583_seen9M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_540_seen999M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_545_seen999M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_586_seen98K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_587_seen995K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_550_seen999M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_520_seen999M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_588_seen9M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_591_seen98K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_592_seen995K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_584_seen99M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_593_seen9M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_579_seen99M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_596_seen98K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_597_seen995K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_598_seen9M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_555_seen999M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_589_seen99M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_601_seen98K
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_602_seen995K
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_594_seen99M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_603_seen9M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_604_seen99M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_606_seen98K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_560_seen999M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_607_seen995K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_599_seen99M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_608_seen9M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_611_seen98K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_612_seen995K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_613_seen9M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_609_seen99M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_614_seen99M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_616_seen98K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_617_seen995K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_618_seen9M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_619_seen99M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_565_seen999M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_621_seen98K
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_622_seen995K
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_623_seen9M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_570_seen999M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_575_seen999M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_626_seen98K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_627_seen995K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_628_seen9M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_624_seen99M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_629_seen99M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_631_seen98K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_632_seen995K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_633_seen9M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_585_seen999M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_634_seen99M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_636_seen98K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_590_seen999M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_637_seen995K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_638_seen9M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_595_seen999M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_641_seen98K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_642_seen995K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_643_seen9M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_644_seen99M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_639_seen99M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_646_seen98K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_647_seen995K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_648_seen9M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_649_seen99M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_605_seen999M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_651_seen98K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_652_seen995K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_653_seen9M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_654_seen99M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_645_seen999M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_656_seen98K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_610_seen999M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_657_seen995K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_658_seen9M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_659_seen99M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_661_seen98K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_662_seen995K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_663_seen9M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_664_seen99M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_650_seen999M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_666_seen98K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_667_seen995K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_668_seen9M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_615_seen999M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_669_seen99M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_671_seen98K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_672_seen995K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_655_seen999M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_673_seen9M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_674_seen99M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_676_seen98K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_677_seen995K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_678_seen9M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_679_seen99M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_2_seen98K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_3_seen995K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_8_seen995K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_7_seen98K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_4_seen9M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_9_seen9M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_12_seen98K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_13_seen995K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_14_seen9M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_18_seen995K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_17_seen98K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_19_seen9M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_22_seen98K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_23_seen995K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_24_seen9M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_5_seen99M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_10_seen99M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_27_seen98K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_28_seen995K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_15_seen99M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_32_seen98K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_33_seen995K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_34_seen9M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_20_seen99M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_25_seen99M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_37_seen98K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_39_seen9M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_30_seen99M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_42_seen98K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_43_seen995K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_35_seen99M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_40_seen99M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_47_seen98K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_48_seen995K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_45_seen99M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_52_seen98K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_50_seen99M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_53_seen995K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_54_seen9M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_55_seen99M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_57_seen98K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_59_seen9M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_60_seen99M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_6_seen999M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_62_seen98K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_11_seen999M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_16_seen999M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_63_seen995K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_64_seen9M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_67_seen98K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_68_seen995K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_26_seen999M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_69_seen9M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_31_seen999M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_72_seen98K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_65_seen99M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_36_seen999M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_73_seen995K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_74_seen9M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_77_seen98K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_78_seen995K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_41_seen999M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_79_seen9M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_46_seen999M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_70_seen99M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_1_seen999M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_82_seen98K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_83_seen995K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_75_seen99M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_84_seen9M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_87_seen98K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_88_seen995K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_89_seen9M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_51_seen999M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_92_seen98K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_93_seen995K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_94_seen9M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_85_seen99M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_56_seen999M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_80_seen99M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_97_seen98K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_98_seen995K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_90_seen99M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_99_seen9M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_102_seen98K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_103_seen995K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_104_seen9M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_95_seen99M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_100_seen99M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_107_seen98K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_105_seen99M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_108_seen995K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_109_seen9M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_110_seen99M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_112_seen98K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_113_seen995K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_114_seen9M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_61_seen999M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_115_seen99M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_117_seen98K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_118_seen995K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_119_seen9M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_66_seen999M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_120_seen99M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_122_seen98K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_123_seen995K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_71_seen999M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_124_seen9M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_76_seen999M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_127_seen98K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_128_seen995K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_129_seen9M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_125_seen99M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_86_seen999M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_132_seen98K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_133_seen995K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_134_seen9M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_130_seen99M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_96_seen999M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_137_seen98K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_138_seen995K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_139_seen9M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_135_seen99M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_140_seen99M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_106_seen999M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_91_seen999M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_142_seen98K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_143_seen995K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_144_seen9M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_147_seen98K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_148_seen995K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_111_seen999M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_149_seen9M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_145_seen99M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_152_seen98K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_153_seen995K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_154_seen9M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_116_seen999M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_81_seen999M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_150_seen99M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_157_seen98K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_158_seen995K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_159_seen9M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_101_seen999M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_155_seen99M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_162_seen98K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_163_seen995K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_164_seen9M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_121_seen999M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_167_seen98K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_168_seen995K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_160_seen99M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_169_seen9M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_165_seen99M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_172_seen98K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_126_seen999M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_173_seen995K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_174_seen9M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_131_seen999M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_177_seen98K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_170_seen99M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_136_seen999M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_178_seen995K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_179_seen9M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_175_seen99M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_182_seen98K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_183_seen995K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_184_seen9M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_141_seen999M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_187_seen98K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_188_seen995K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_185_seen99M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_189_seen9M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_180_seen99M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_192_seen98K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_193_seen995K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_194_seen9M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_190_seen99M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_195_seen99M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_197_seen98K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_198_seen995K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_199_seen9M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_146_seen999M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_200_seen99M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_202_seen98K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_203_seen995K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_204_seen9M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_151_seen999M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_156_seen999M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_207_seen98K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_208_seen995K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_205_seen99M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_209_seen9M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_210_seen99M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_166_seen999M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_212_seen98K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_213_seen995K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_214_seen9M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_171_seen999M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_217_seen98K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_218_seen995K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_215_seen99M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_219_seen9M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_176_seen999M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_222_seen98K
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_223_seen995K
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_224_seen9M
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_3_seen98K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_3_seen98K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_8_seen98K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_4_seen995K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_9_seen995K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_13_seen98K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_10_seen9M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_14_seen995K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_5_seen9M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_18_seen98K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_15_seen9M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_19_seen995K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_23_seen98K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_20_seen9M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768
