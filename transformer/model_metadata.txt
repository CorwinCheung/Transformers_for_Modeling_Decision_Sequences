Model name: model_seen92K
  Num Parameters: 101,120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 92,160

Total batch size: 3,072

Max steps: 30

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: model_seen921K
  Num Parameters: 101,120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 921,600

Total batch size: 3,072

Max steps: 300

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: model_seen92M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 92,160,000

Total batch size: 3,072

Max steps: 30,000

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: model_seen921M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 921600000

Total batch size: 3,072

Max steps: 300,000

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_seen9M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9216000

Total batch size: 6,144

Max steps: 1,500

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_seen9M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9216000

Total batch size: 6,144

Max steps: 1,500

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_seen9M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9216000

Total batch size: 6,144

Max steps: 1,500

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_seen92M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 92160000

Total batch size: 6,144

Max steps: 15,000

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64
