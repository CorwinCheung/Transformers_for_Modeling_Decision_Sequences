Model name: model_seen92K
  Num Parameters: 101,120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 92,160

Total batch size: 3,072

Max steps: 30

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: model_seen921K
  Num Parameters: 101,120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 921,600

Total batch size: 3,072

Max steps: 300

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: model_seen92M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 92,160,000

Total batch size: 3,072

Max steps: 30,000

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: model_seen921M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 921600000

Total batch size: 3,072

Max steps: 300,000

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_seen9M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9216000

Total batch size: 6,144

Max steps: 1,500

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_seen9M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9216000

Total batch size: 6,144

Max steps: 1,500

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_seen9M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9216000

Total batch size: 6,144

Max steps: 1,500

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_seen92M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 92160000

Total batch size: 6,144

Max steps: 15,000

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_1_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_1_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_2_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_3_seen9M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_1_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_2_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_3_seen9M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_6_seen1M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 1099776

Total batch size: 6,144

Max steps: 179

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_7_seen995K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_8_seen9M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_11_seen98K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_4_seen99M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_12_seen995K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_13_seen9M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_4_seen99M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_9_seen99M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_16_seen98K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_17_seen995K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_18_seen9M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_14_seen99M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_19_seen99M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_21_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_22_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_23_seen9M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_24_seen99M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_5_seen999M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_26_seen98K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_27_seen995K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_10_seen999M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_28_seen9M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_15_seen999M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_31_seen98K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_32_seen995K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_29_seen99M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_33_seen9M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_34_seen99M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_36_seen98K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_37_seen995K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_38_seen9M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_39_seen99M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_25_seen999M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_41_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_42_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_20_seen999M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_43_seen9M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_1_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_12_seen995K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_2_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_7_seen995K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_6_seen1M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 1099776

Total batch size: 6,144

Max steps: 179

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_11_seen98K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_8_seen9M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_3_seen9M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_16_seen98K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_17_seen995K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_13_seen9M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_21_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_22_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_18_seen9M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_26_seen98K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_23_seen9M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_27_seen995K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_28_seen9M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_9_seen99M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_4_seen99M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_14_seen99M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_32_seen995K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_33_seen9M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_24_seen99M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_19_seen99M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_36_seen98K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_37_seen995K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_29_seen99M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_41_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_42_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_43_seen9M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_34_seen99M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_46_seen98K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_47_seen995K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_48_seen9M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_39_seen99M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_44_seen99M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_51_seen98K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_52_seen995K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_53_seen9M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_49_seen99M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_54_seen99M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_57_seen995K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_58_seen9M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_5_seen999M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_61_seen98K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_10_seen999M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_62_seen995K
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_15_seen999M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_25_seen999M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_66_seen98K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_67_seen995K
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_68_seen9M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_30_seen999M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_71_seen98K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_72_seen995K
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_64_seen99M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_35_seen999M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_76_seen98K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_77_seen995K
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_74_seen99M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_81_seen98K
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_45_seen999M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_83_seen9M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_79_seen99M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_86_seen98K
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_87_seen995K
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_88_seen9M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_50_seen999M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_20_seen999M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_55_seen999M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_91_seen98K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_92_seen995K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_93_seen9M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_84_seen99M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_96_seen98K
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_97_seen995K
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_89_seen99M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_98_seen9M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_40_seen999M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_94_seen99M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_102_seen995K
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_103_seen9M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_60_seen999M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_106_seen98K
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_108_seen9M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_104_seen99M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_99_seen99M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_111_seen98K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_112_seen995K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_113_seen9M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_109_seen99M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_116_seen98K
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_114_seen99M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_118_seen9M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_65_seen999M
  Num Parameters: 3408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_70_seen999M
  Num Parameters: 50496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_121_seen98K
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_122_seen995K
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_123_seen9M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_75_seen999M
  Num Parameters: 791808

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_119_seen99M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_126_seen98K
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_127_seen995K
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_128_seen9M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_124_seen99M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_80_seen999M
  Num Parameters: 7094016

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_131_seen98K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_132_seen995K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_129_seen99M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_136_seen98K
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_137_seen995K
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_138_seen9M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_134_seen99M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_139_seen99M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_141_seen98K
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_142_seen995K
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_143_seen9M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_85_seen999M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_144_seen99M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_146_seen98K
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_147_seen995K
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_148_seen9M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_95_seen999M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_90_seen999M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_151_seen98K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_152_seen995K
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_153_seen9M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_149_seen99M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_110_seen999M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_156_seen98K
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_157_seen995K
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_154_seen99M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_158_seen9M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_115_seen999M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_161_seen98K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_159_seen99M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_162_seen995K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_163_seen9M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_164_seen99M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_166_seen98K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_167_seen995K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_130_seen999M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_125_seen999M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_168_seen9M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_171_seen98K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_172_seen995K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_173_seen9M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_100_seen999M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_135_seen999M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_176_seen98K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_177_seen995K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_178_seen9M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_169_seen99M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_140_seen999M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_174_seen99M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_181_seen98K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_182_seen995K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_183_seen9M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_120_seen999M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_186_seen98K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_184_seen99M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_187_seen995K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_188_seen9M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_150_seen999M
  Num Parameters: 100480

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_179_seen99M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_191_seen98K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_192_seen995K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_145_seen999M
  Num Parameters: 6688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_193_seen9M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_196_seen98K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_197_seen995K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_198_seen9M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_155_seen999M
  Num Parameters: 1581568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_189_seen99M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_201_seen98K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_202_seen995K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_203_seen9M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_194_seen99M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_160_seen999M
  Num Parameters: 14181888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_204_seen99M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_206_seen98K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_207_seen995K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_199_seen99M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_208_seen9M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_211_seen98K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_212_seen995K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_213_seen9M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_209_seen99M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_214_seen99M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_216_seen98K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_217_seen995K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_218_seen9M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_219_seen99M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_165_seen999M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_221_seen98K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_222_seen995K
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_223_seen9M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_170_seen999M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_224_seen99M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_226_seen98K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_227_seen995K
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_228_seen9M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_175_seen999M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_229_seen99M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_231_seen98K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_232_seen995K
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_185_seen999M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_233_seen9M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_234_seen99M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_236_seen98K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_237_seen995K
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_190_seen999M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_238_seen9M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_195_seen999M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_241_seen98K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_242_seen995K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_243_seen9M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_239_seen99M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_205_seen999M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_246_seen98K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_247_seen995K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_248_seen9M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_244_seen99M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_210_seen999M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_251_seen98K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_252_seen995K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_253_seen9M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_215_seen999M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_249_seen99M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_256_seen98K
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_257_seen995K
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_258_seen9M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_254_seen99M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_180_seen999M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_261_seen98K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_262_seen995K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_263_seen9M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_220_seen999M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_200_seen999M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_266_seen98K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_230_seen999M
  Num Parameters: 200448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_267_seen995K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_225_seen999M
  Num Parameters: 13248

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_268_seen9M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_271_seen98K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_272_seen995K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_264_seen99M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_273_seen9M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_259_seen99M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_276_seen98K
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_277_seen995K
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_235_seen999M
  Num Parameters: 3161088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_278_seen9M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_269_seen99M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_281_seen98K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_282_seen995K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_283_seen9M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_274_seen99M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_240_seen999M
  Num Parameters: 28357632

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_286_seen98K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_284_seen99M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_287_seen995K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_288_seen9M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_279_seen99M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_291_seen98K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_292_seen995K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_293_seen9M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_289_seen99M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_294_seen99M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_297_seen995K
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_298_seen9M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_299_seen99M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_245_seen999M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_301_seen98K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_302_seen995K
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_303_seen9M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_250_seen999M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_304_seen99M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_306_seen98K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_307_seen995K
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_308_seen9M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_255_seen999M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_309_seen99M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_311_seen98K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_312_seen995K
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_313_seen9M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_265_seen999M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_270_seen999M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_316_seen98K
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_317_seen995K
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_314_seen99M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_318_seen9M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_275_seen999M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_321_seen98K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_322_seen995K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_323_seen9M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_324_seen99M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_319_seen99M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_326_seen98K
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_327_seen995K
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_328_seen9M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_329_seen99M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_285_seen999M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_331_seen98K
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_332_seen995K
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_290_seen999M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_333_seen9M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_325_seen999M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_336_seen98K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_337_seen995K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_338_seen9M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_334_seen99M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_339_seen99M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_341_seen98K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_342_seen995K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_343_seen9M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_344_seen99M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_295_seen999M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_346_seen98K
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_347_seen995K
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_330_seen999M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_348_seen9M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_349_seen99M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_351_seen98K
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_352_seen995K
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_353_seen9M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_354_seen99M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_335_seen999M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_356_seen98K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_357_seen995K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_358_seen9M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_359_seen99M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_340_seen999M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_345_seen999M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_361_seen98K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_362_seen995K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_363_seen9M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_364_seen99M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_366_seen98K
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_367_seen995K
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_368_seen9M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_350_seen999M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_369_seen99M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_372_seen995K
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_373_seen9M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_355_seen999M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_374_seen99M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_376_seen98K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_377_seen995K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_378_seen9M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_379_seen99M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_365_seen999M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_381_seen98K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_382_seen995K
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_383_seen9M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_360_seen999M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_260_seen999M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_370_seen999M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_384_seen99M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_387_seen995K
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_388_seen9M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_391_seen98K
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_392_seen995K
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_393_seen9M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_389_seen99M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_396_seen98K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_397_seen995K
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_398_seen9M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_375_seen999M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_399_seen99M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_401_seen98K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_402_seen995K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_403_seen9M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_380_seen999M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_404_seen99M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_406_seen98K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_407_seen995K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_408_seen9M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_300_seen999M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_409_seen99M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_411_seen98K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_412_seen995K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_310_seen999M
  Num Parameters: 400384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_385_seen999M
  Num Parameters: 3424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_390_seen999M
  Num Parameters: 50560

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_416_seen98K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_417_seen995K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_418_seen9M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_414_seen99M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_280_seen999M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_421_seen98K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_422_seen995K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_395_seen999M
  Num Parameters: 792064

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_423_seen9M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_426_seen98K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_427_seen995K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_428_seen9M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_424_seen99M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_419_seen99M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_431_seen98K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_432_seen995K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_429_seen99M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_433_seen9M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_400_seen999M
  Num Parameters: 7094784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_436_seen98K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_437_seen995K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_438_seen9M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_434_seen99M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_315_seen999M
  Num Parameters: 6320128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_441_seen98K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_439_seen99M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_442_seen995K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_443_seen9M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_444_seen99M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_446_seen98K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_405_seen999M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_447_seen995K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_448_seen9M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_449_seen99M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_451_seen98K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_452_seen995K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_453_seen9M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_305_seen999M
  Num Parameters: 26368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_415_seen999M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_454_seen99M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_456_seen98K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_457_seen995K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_458_seen9M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_425_seen999M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_459_seen99M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_461_seen98K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_462_seen995K
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_463_seen9M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_410_seen999M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_466_seen98K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_467_seen995K
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_468_seen9M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_430_seen999M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_471_seen98K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_469_seen99M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_472_seen995K
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_435_seen999M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_473_seen9M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_476_seen98K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_477_seen995K
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_478_seen9M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_474_seen99M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_479_seen99M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_481_seen98K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_482_seen995K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_483_seen9M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_445_seen999M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_320_seen999M
  Num Parameters: 56709120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 2

GPTConfig parameters:
  Block size: 2
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_486_seen98K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_487_seen995K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_420_seen999M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_488_seen9M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_450_seen999M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_484_seen99M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_491_seen98K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_492_seen995K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_493_seen9M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_489_seen99M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_496_seen98K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_497_seen995K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_494_seen99M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_498_seen9M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_440_seen999M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_501_seen98K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_502_seen995K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_503_seen9M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_460_seen999M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_455_seen999M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_506_seen98K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_507_seen995K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_508_seen9M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_470_seen999M
  Num Parameters: 100544

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_465_seen999M
  Num Parameters: 6704

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_511_seen98K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_504_seen99M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_512_seen995K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_499_seen99M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_513_seen9M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_516_seen98K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_517_seen995K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_475_seen999M
  Num Parameters: 1581824

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_518_seen9M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_509_seen99M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_514_seen99M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_521_seen98K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_522_seen995K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_523_seen9M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_480_seen999M
  Num Parameters: 14182656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_526_seen98K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_527_seen995K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_528_seen9M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_519_seen99M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_524_seen99M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_531_seen98K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_532_seen995K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_533_seen9M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_529_seen99M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_534_seen99M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_536_seen98K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_537_seen995K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_538_seen9M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_539_seen99M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_485_seen999M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_541_seen98K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_542_seen995K
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_543_seen9M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_490_seen999M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_495_seen999M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_546_seen98K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_547_seen995K
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_548_seen9M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_544_seen99M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_549_seen99M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_551_seen98K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_552_seen995K
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_553_seen9M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_505_seen999M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_554_seen99M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_510_seen999M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_515_seen999M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_556_seen98K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_557_seen995K
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_558_seen9M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_561_seen98K
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_562_seen995K
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_563_seen9M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_559_seen99M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_525_seen999M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_566_seen98K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_567_seen995K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_530_seen999M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_568_seen9M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_564_seen99M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_571_seen98K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_572_seen995K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_573_seen9M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_535_seen999M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_569_seen99M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_576_seen98K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_577_seen995K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_578_seen9M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_574_seen99M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_500_seen999M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_581_seen98K
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_583_seen9M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_540_seen999M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_545_seen999M
  Num Parameters: 13264

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_586_seen98K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_587_seen995K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_550_seen999M
  Num Parameters: 200512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_520_seen999M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_588_seen9M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_591_seen98K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_592_seen995K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_584_seen99M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_593_seen9M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_579_seen99M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_596_seen98K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_597_seen995K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_598_seen9M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_555_seen999M
  Num Parameters: 3161344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_589_seen99M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_601_seen98K
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_602_seen995K
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_594_seen99M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_603_seen9M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_604_seen99M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_606_seen98K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_560_seen999M
  Num Parameters: 28358400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_607_seen995K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_599_seen99M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_608_seen9M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_611_seen98K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_612_seen995K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_613_seen9M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_609_seen99M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_614_seen99M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_616_seen98K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_617_seen995K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_618_seen9M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_619_seen99M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_565_seen999M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_621_seen98K
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_622_seen995K
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_623_seen9M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_570_seen999M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_575_seen999M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_626_seen98K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_627_seen995K
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_628_seen9M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_624_seen99M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_629_seen99M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_631_seen98K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_632_seen995K
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_633_seen9M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_585_seen999M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_634_seen99M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_636_seen98K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_590_seen999M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_637_seen995K
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_638_seen9M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_595_seen999M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_641_seen98K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_642_seen995K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_643_seen9M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_644_seen99M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_639_seen99M
  Num Parameters: 56709888

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_646_seen98K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_647_seen995K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_648_seen9M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_649_seen99M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_605_seen999M
  Num Parameters: 26384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_651_seen98K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_652_seen995K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_653_seen9M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_654_seen99M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_645_seen999M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_656_seen98K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_610_seen999M
  Num Parameters: 400448

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_657_seen995K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_658_seen9M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_659_seen99M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_661_seen98K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_662_seen995K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_663_seen9M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_664_seen99M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_650_seen999M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_666_seen98K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_667_seen995K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_668_seen9M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_615_seen999M
  Num Parameters: 6320384

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 3

GPTConfig parameters:
  Block size: 3
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_669_seen99M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_671_seen98K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_672_seen995K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_655_seen999M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_673_seen9M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_674_seen99M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_676_seen98K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_677_seen995K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_678_seen9M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_679_seen99M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_2_seen98K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_3_seen995K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_8_seen995K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_7_seen98K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_4_seen9M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_9_seen9M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_12_seen98K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_13_seen995K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_14_seen9M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_18_seen995K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_17_seen98K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_19_seen9M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_22_seen98K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_23_seen995K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_24_seen9M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_5_seen99M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_10_seen99M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_27_seen98K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_28_seen995K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_15_seen99M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_32_seen98K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_33_seen995K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_34_seen9M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_20_seen99M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_25_seen99M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_37_seen98K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_39_seen9M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_30_seen99M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_42_seen98K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_43_seen995K
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_35_seen99M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_40_seen99M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_47_seen98K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_48_seen995K
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_45_seen99M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_52_seen98K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_50_seen99M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_53_seen995K
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_54_seen9M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_55_seen99M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_57_seen98K
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_59_seen9M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_60_seen99M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_6_seen999M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_62_seen98K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_11_seen999M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_16_seen999M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_63_seen995K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_64_seen9M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_67_seen98K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_68_seen995K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_26_seen999M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_69_seen9M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_31_seen999M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_72_seen98K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_65_seen99M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_36_seen999M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_73_seen995K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_74_seen9M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_77_seen98K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_78_seen995K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_41_seen999M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_79_seen9M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_46_seen999M
  Num Parameters: 3440

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_70_seen99M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_1_seen999M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_82_seen98K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_83_seen995K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_75_seen99M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_84_seen9M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_87_seen98K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_88_seen995K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_89_seen9M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_51_seen999M
  Num Parameters: 50624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_92_seen98K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_93_seen995K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_94_seen9M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_85_seen99M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_56_seen999M
  Num Parameters: 792320

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_80_seen99M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_97_seen98K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_98_seen995K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_90_seen99M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_99_seen9M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_102_seen98K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_103_seen995K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_104_seen9M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_95_seen99M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_100_seen99M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_107_seen98K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_105_seen99M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_108_seen995K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_109_seen9M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_110_seen99M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_112_seen98K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_113_seen995K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_114_seen9M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_61_seen999M
  Num Parameters: 7095552

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_115_seen99M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_117_seen98K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_118_seen995K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_119_seen9M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_66_seen999M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_120_seen99M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_122_seen98K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_123_seen995K
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_71_seen999M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_124_seen9M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_76_seen999M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_127_seen98K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_128_seen995K
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_129_seen9M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_125_seen99M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_86_seen999M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_132_seen98K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_133_seen995K
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_134_seen9M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_130_seen99M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_96_seen999M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_137_seen98K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_138_seen995K
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_139_seen9M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_135_seen99M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_140_seen99M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_106_seen999M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_91_seen999M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_142_seen98K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_143_seen995K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_144_seen9M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_147_seen98K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_148_seen995K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_111_seen999M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_149_seen9M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_145_seen99M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_152_seen98K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_153_seen995K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_154_seen9M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_116_seen999M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_81_seen999M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_150_seen99M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_157_seen98K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_158_seen995K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_159_seen9M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_101_seen999M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_155_seen99M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_162_seen98K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_163_seen995K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_164_seen9M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_121_seen999M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_167_seen98K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_168_seen995K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_160_seen99M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_169_seen9M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_165_seen99M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_172_seen98K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_126_seen999M
  Num Parameters: 6720

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_173_seen995K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_174_seen9M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_131_seen999M
  Num Parameters: 100608

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_177_seen98K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_170_seen99M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_136_seen999M
  Num Parameters: 1582080

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_178_seen995K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_179_seen9M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_175_seen99M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_182_seen98K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_183_seen995K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_184_seen9M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_141_seen999M
  Num Parameters: 14183424

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_187_seen98K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_188_seen995K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_185_seen99M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_189_seen9M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_180_seen99M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_192_seen98K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_193_seen995K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_194_seen9M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_190_seen99M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_195_seen99M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_197_seen98K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_198_seen995K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_199_seen9M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_146_seen999M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_200_seen99M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_202_seen98K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_203_seen995K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_204_seen9M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_151_seen999M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_156_seen999M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_207_seen98K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_208_seen995K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_205_seen99M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_209_seen9M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_210_seen99M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_166_seen999M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_212_seen98K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_213_seen995K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_214_seen9M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_171_seen999M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_217_seen98K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_218_seen995K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_215_seen99M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_219_seen9M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_176_seen999M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_222_seen98K
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_223_seen995K
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_224_seen9M
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_3_seen98K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_3_seen98K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_8_seen98K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_4_seen995K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_9_seen995K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_13_seen98K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_10_seen9M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_14_seen995K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_5_seen9M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_18_seen98K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_15_seen9M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_19_seen995K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_23_seen98K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_20_seen9M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_24_seen995K
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_25_seen9M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_11_seen99M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_6_seen99M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_16_seen99M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_28_seen98K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_29_seen995K
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_30_seen9M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_33_seen98K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_21_seen99M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_34_seen995K
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_26_seen99M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_35_seen9M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_1_seen99M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_38_seen98K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_39_seen995K
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_40_seen9M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_31_seen99M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_43_seen98K
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_44_seen995K
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_36_seen99M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_36_seen99M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_45_seen9M
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_41_seen99M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_48_seen98K
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_49_seen995K
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_50_seen9M
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_46_seen99M
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_51_seen99M
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_53_seen98K
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_54_seen995K
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_55_seen9M
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_56_seen99M
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_17_seen999M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_58_seen98K
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_12_seen999M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_7_seen999M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_7_seen999M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_59_seen995K
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_60_seen9M
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_27_seen999M
  Num Parameters: 13280

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_63_seen98K
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_32_seen999M
  Num Parameters: 200576

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_64_seen995K
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_64_seen995K
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_65_seen9M
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_37_seen999M
  Num Parameters: 3161600

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_22_seen999M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_68_seen98K
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_69_seen995K
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_70_seen9M
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_73_seen98K
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_74_seen995K
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_75_seen9M
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_66_seen99M
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_71_seen99M
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_78_seen98K
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_42_seen999M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_79_seen995K
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_61_seen99M
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_80_seen9M
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_76_seen99M
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_83_seen98K
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_84_seen995K
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_85_seen9M
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_86_seen99M
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_2_seen999M
  Num Parameters: 28359168

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_88_seen98K
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_88_seen98K
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_89_seen995K
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_90_seen9M
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_81_seen99M
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_93_seen98K
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_94_seen995K
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_95_seen9M
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_91_seen99M
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_96_seen99M
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_98_seen98K
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_47_seen999M
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_99_seen995K
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_100_seen9M
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_101_seen99M
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_103_seen98K
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_52_seen999M
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_104_seen995K
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_105_seen9M
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_106_seen99M
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_108_seen98K
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_109_seen995K
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_57_seen999M
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_110_seen9M
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_111_seen99M
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_113_seen98K
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_114_seen995K
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_115_seen9M
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_67_seen999M
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_116_seen99M
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_118_seen98K
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_119_seen995K
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_72_seen999M
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_120_seen9M
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_77_seen999M
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_121_seen99M
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_87_seen999M
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_92_seen999M
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_443_seen98K
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_444_seen995K
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_445_seen9M
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_448_seen98K
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_449_seen995K
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_450_seen9M
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_446_seen99M
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_453_seen98K
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_451_seen99M
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_454_seen995K
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_455_seen9M
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_456_seen99M
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_458_seen98K
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_459_seen995K
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_97_seen999M
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_460_seen9M
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_461_seen99M
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_463_seen98K
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_464_seen995K
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_465_seen9M
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_466_seen99M
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_447_seen999M
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_468_seen98K
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_469_seen995K
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_452_seen999M
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_470_seen9M
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_471_seen99M
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_457_seen999M
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_474_seen995K
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_473_seen98K
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_475_seen9M
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_476_seen99M
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_478_seen98K
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_479_seen995K
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_480_seen9M
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_481_seen99M
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_467_seen999M
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_462_seen999M
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_483_seen98K
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_484_seen995K
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_485_seen9M
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_486_seen99M
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_472_seen999M
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_488_seen98K
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_489_seen995K
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_490_seen9M
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_491_seen99M
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_477_seen999M
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_493_seen98K
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_494_seen995K
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_495_seen9M
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_102_seen999M
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_496_seen99M
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_498_seen98K
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_499_seen995K
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_500_seen9M
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_107_seen999M
  Num Parameters: 26400

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_503_seen98K
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_501_seen99M
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_504_seen995K
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_505_seen9M
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_506_seen99M
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_508_seen98K
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_509_seen995K
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_510_seen9M
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_487_seen999M
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_511_seen99M
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_482_seen999M
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_513_seen98K
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_514_seen995K
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_515_seen9M
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_492_seen999M
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_518_seen98K
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_519_seen995K
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_516_seen99M
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_520_seen9M
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_497_seen999M
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_112_seen999M
  Num Parameters: 400512

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_523_seen98K
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_524_seen995K
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_521_seen99M
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_525_seen9M
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_528_seen98K
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_62_seen999M
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_529_seen995K
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_530_seen9M
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_526_seen99M
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_533_seen98K
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_502_seen999M
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_534_seen995K
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_535_seen9M
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_531_seen99M
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_507_seen999M
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_538_seen98K
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_539_seen995K
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_540_seen9M
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_536_seen99M
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_543_seen98K
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_544_seen995K
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_545_seen9M
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_512_seen999M
  Num Parameters: 50880

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_541_seen99M
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_548_seen98K
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_549_seen995K
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_546_seen99M
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_550_seen9M
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_517_seen999M
  Num Parameters: 793344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_553_seen98K
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_554_seen995K
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_555_seen9M
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_551_seen99M
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_522_seen999M
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_558_seen98K
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_556_seen99M
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_559_seen995K
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_560_seen9M
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_82_seen999M
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_561_seen99M
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_563_seen98K
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_564_seen995K
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_527_seen999M
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_565_seen9M
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_568_seen98K
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_569_seen995K
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_532_seen999M
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_570_seen9M
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_566_seen99M
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_573_seen98K
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_574_seen995K
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_571_seen99M
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_537_seen999M
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_575_seen9M
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_578_seen98K
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_117_seen999M
  Num Parameters: 6320640

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_579_seen995K
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_580_seen9M
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_576_seen99M
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_583_seen98K
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_584_seen995K
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_581_seen99M
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_585_seen9M
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_547_seen999M
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_588_seen98K
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_589_seen995K
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_590_seen9M
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_552_seen999M
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_586_seen99M
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_593_seen98K
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_594_seen995K
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_557_seen999M
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_595_seen9M
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_591_seen99M
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_598_seen98K
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_599_seen995K
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_600_seen9M
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_596_seen99M
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_601_seen99M
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_603_seen98K
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_542_seen999M
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_604_seen995K
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_605_seen9M
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_567_seen999M
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_608_seen98K
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_609_seen995K
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_572_seen999M
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_610_seen9M
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_606_seen99M
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_613_seen98K
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_577_seen999M
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_614_seen995K
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_615_seen9M
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_611_seen99M
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_618_seen98K
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_619_seen995K
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_616_seen99M
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_620_seen9M
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_562_seen999M
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_623_seen98K
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_587_seen999M
  Num Parameters: 6784

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_624_seen995K
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_582_seen999M
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_625_seen9M
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_628_seen98K
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_592_seen999M
  Num Parameters: 100864

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_629_seen995K
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_630_seen9M
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_597_seen999M
  Num Parameters: 1583104

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_626_seen99M
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_633_seen98K
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_621_seen99M
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_634_seen995K
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_635_seen9M
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_638_seen98K
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_631_seen99M
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_122_seen999M
  Num Parameters: 56710656

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 4

GPTConfig parameters:
  Block size: 4
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_639_seen995K
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_640_seen9M
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_643_seen98K
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_644_seen995K
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_636_seen99M
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_645_seen9M
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_602_seen999M
  Num Parameters: 14186496

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_648_seen98K
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_646_seen99M
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_649_seen995K
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_641_seen99M
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_650_seen9M
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_653_seen98K
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_654_seen995K
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_655_seen9M
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_651_seen99M
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_656_seen99M
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_658_seen98K
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_659_seen995K
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_607_seen999M
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_660_seen9M
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_612_seen999M
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_663_seen98K
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_664_seen995K
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_661_seen99M
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_617_seen999M
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_665_seen9M
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_668_seen98K
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_669_seen995K
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_670_seen9M
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_666_seen99M
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_627_seen999M
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_632_seen999M
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_674_seen995K
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_673_seen98K
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_675_seen9M
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_637_seen999M
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_671_seen99M
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_678_seen98K
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_678_seen98K
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_679_seen995K
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_680_seen9M
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_676_seen99M
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_683_seen98K
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_684_seen995K
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_685_seen9M
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_647_seen999M
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_681_seen99M
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_688_seen98K
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_689_seen995K
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_652_seen999M
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_690_seen9M
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_686_seen99M
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_657_seen999M
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_693_seen98K
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_694_seen995K
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_695_seen9M
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_691_seen99M
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_698_seen98K
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_699_seen995K
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_700_seen9M
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_696_seen99M
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_622_seen999M
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_703_seen98K
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_704_seen995K
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_667_seen999M
  Num Parameters: 13344

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_705_seen9M
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_662_seen999M
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_708_seen98K
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_642_seen999M
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_709_seen995K
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_710_seen9M
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_701_seen99M
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_706_seen99M
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_713_seen98K
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_714_seen995K
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_672_seen999M
  Num Parameters: 200832

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_715_seen9M
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_677_seen999M
  Num Parameters: 3162624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_718_seen98K
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_719_seen995K
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_711_seen99M
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_720_seen9M
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_723_seen98K
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_724_seen995K
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_725_seen9M
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_716_seen99M
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_726_seen99M
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_728_seen98K
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_721_seen99M
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_729_seen995K
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_682_seen999M
  Num Parameters: 28362240

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_730_seen9M
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_733_seen98K
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_734_seen995K
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_735_seen9M
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_731_seen99M
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_736_seen99M
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_738_seen98K
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_739_seen995K
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_740_seen9M
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_687_seen999M
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_692_seen999M
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_743_seen98K
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_744_seen995K
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_745_seen9M
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_697_seen999M
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_741_seen99M
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_748_seen98K
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_749_seen995K
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_750_seen9M
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_746_seen99M
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_751_seen99M
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_753_seen98K
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_754_seen995K
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_755_seen9M
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_707_seen999M
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_712_seen999M
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_758_seen98K
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_756_seen99M
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_759_seen995K
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_717_seen999M
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_760_seen9M
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_763_seen98K
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_764_seen995K
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_765_seen9M
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_766_seen99M
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_761_seen99M
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_768_seen98K
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_769_seen995K
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_770_seen9M
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_727_seen999M
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_771_seen99M
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_773_seen98K
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_774_seen995K
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_775_seen9M
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_767_seen999M
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_776_seen99M
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_732_seen999M
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_778_seen98K
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_779_seen995K
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_780_seen9M
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_781_seen99M
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_783_seen98K
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_784_seen995K
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_785_seen9M
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_737_seen999M
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_772_seen999M
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_786_seen99M
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_788_seen98K
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_789_seen995K
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_790_seen9M
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_791_seen99M
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_793_seen98K
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_777_seen999M
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_794_seen995K
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_795_seen9M
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_796_seen99M
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_798_seen98K
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_799_seen995K
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_800_seen9M
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_801_seen99M
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_787_seen999M
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_803_seen98K
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_782_seen999M
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_804_seen995K
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_792_seen999M
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_805_seen9M
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_808_seen98K
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_806_seen99M
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_809_seen995K
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_810_seen9M
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_811_seen99M
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_797_seen999M
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_813_seen98K
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_814_seen995K
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_815_seen9M
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_816_seen99M
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_818_seen98K
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_819_seen995K
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_820_seen9M
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_821_seen99M
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_807_seen999M
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_747_seen999M
  Num Parameters: 26464

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_823_seen98K
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_824_seen995K
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_825_seen9M
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_812_seen999M
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_752_seen999M
  Num Parameters: 400768

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_802_seen999M
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_826_seen99M
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_828_seen98K
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_829_seen995K
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_830_seen9M
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_817_seen999M
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_702_seen999M
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_833_seen98K
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_834_seen995K
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_831_seen99M
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_835_seen9M
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_838_seen98K
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_839_seen995K
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_840_seen9M
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_836_seen99M
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_843_seen98K
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_844_seen995K
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_845_seen9M
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_841_seen99M
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_848_seen98K
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_849_seen995K
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_846_seen99M
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_742_seen999M
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_757_seen999M
  Num Parameters: 6321664

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_850_seen9M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_853_seen98K
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_854_seen995K
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_855_seen9M
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_851_seen99M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_858_seen98K
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_822_seen999M
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_859_seen995K
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_856_seen99M
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_860_seen9M
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_827_seen999M
  Num Parameters: 3568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_863_seen98K
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_864_seen995K
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_865_seen9M
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_832_seen999M
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_868_seen98K
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_837_seen999M
  Num Parameters: 794368

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_861_seen99M
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_869_seen995K
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_866_seen99M
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_870_seen9M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_873_seen98K
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_874_seen995K
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_875_seen9M
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_871_seen99M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_878_seen98K
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_722_seen999M
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_842_seen999M
  Num Parameters: 7101696

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_876_seen99M
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_879_seen995K
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_883_seen98K
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_880_seen9M
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_884_seen995K
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_885_seen9M
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_847_seen999M
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_881_seen99M
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_888_seen98K
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_886_seen99M
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_889_seen995K
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_890_seen9M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_893_seen98K
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_894_seen995K
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_852_seen999M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_891_seen99M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_895_seen9M
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_898_seen98K
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_857_seen999M
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_899_seen995K
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_900_seen9M
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_896_seen99M
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_903_seen98K
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_904_seen995K
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_905_seen9M
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_901_seen99M
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_867_seen999M
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_908_seen98K
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_906_seen99M
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_909_seen995K
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_872_seen999M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_910_seen9M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_913_seen98K
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_914_seen995K
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_877_seen999M
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_915_seen9M
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_911_seen99M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_918_seen98K
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_919_seen995K
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_916_seen99M
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_920_seen9M
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_887_seen999M
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_923_seen98K
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_924_seen995K
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_921_seen99M
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_892_seen999M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_925_seen9M
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_928_seen98K
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_929_seen995K
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_862_seen999M
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_897_seen999M
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_930_seen9M
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_926_seen99M
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_933_seen98K
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_934_seen995K
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_935_seen9M
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_931_seen99M
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_762_seen999M
  Num Parameters: 56713728

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_938_seen98K
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_939_seen995K
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_907_seen999M
  Num Parameters: 6848

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_940_seen9M
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_936_seen99M
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_943_seen98K
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_944_seen995K
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_945_seen9M
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_882_seen999M
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_948_seen98K
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_902_seen999M
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_912_seen999M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_949_seen995K
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_950_seen9M
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_946_seen99M
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_917_seen999M
  Num Parameters: 1584128

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_953_seen98K
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_954_seen995K
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_941_seen99M
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_955_seen9M
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_958_seen98K
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_959_seen995K
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_951_seen99M
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_960_seen9M
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_956_seen99M
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_963_seen98K
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_964_seen995K
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_965_seen9M
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_966_seen99M
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_961_seen99M
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_968_seen98K
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_969_seen995K
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_922_seen999M
  Num Parameters: 14189568

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_970_seen9M
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_973_seen98K
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_974_seen995K
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_975_seen9M
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_971_seen99M
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_976_seen99M
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_927_seen999M
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_978_seen98K
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_979_seen995K
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_980_seen9M
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_932_seen999M
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_937_seen999M
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_983_seen98K
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_984_seen995K
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_985_seen9M
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_981_seen99M
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_988_seen98K
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_989_seen995K
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_947_seen999M
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_986_seen99M
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_990_seen9M
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_952_seen999M
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_993_seen98K
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_991_seen99M
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_994_seen995K
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_995_seen9M
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_957_seen999M
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_998_seen98K
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_999_seen995K
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_1000_seen9M
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_996_seen99M
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_1003_seen98K
  Num Parameters: 26528

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_1004_seen995K
  Num Parameters: 26528

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_967_seen999M
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_1001_seen99M
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_1005_seen9M
  Num Parameters: 26528

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_972_seen999M
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 64

Model name: wandb_model_task_1008_seen98K
  Num Parameters: 401024

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_1009_seen995K
  Num Parameters: 401024

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_1010_seen9M
  Num Parameters: 401024

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_977_seen999M
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_1006_seen99M
  Num Parameters: 26528

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_1013_seen98K
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_1014_seen995K
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_1011_seen99M
  Num Parameters: 401024

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_1015_seen9M
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_1018_seen98K
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_1019_seen995K
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_1016_seen99M
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_1020_seen9M
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_987_seen999M
  Num Parameters: 13408

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_1023_seen98K
  Num Parameters: 26528

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_1024_seen995K
  Num Parameters: 26528

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_942_seen999M
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_992_seen999M
  Num Parameters: 201088

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_1025_seen9M
  Num Parameters: 26528

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_1028_seen98K
  Num Parameters: 401024

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_997_seen999M
  Num Parameters: 3163648

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_1029_seen995K
  Num Parameters: 401024

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_1030_seen9M
  Num Parameters: 401024

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_962_seen999M
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_1026_seen99M
  Num Parameters: 26528

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_1021_seen99M
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_1033_seen98K
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_982_seen999M
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_1034_seen995K
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_1035_seen9M
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_1038_seen98K
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_1031_seen99M
  Num Parameters: 401024

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_1039_seen995K
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_1040_seen9M
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_1043_seen98K
  Num Parameters: 26528

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_1036_seen99M
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_1041_seen99M
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_1053_seen98K
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_1046_seen99M
  Num Parameters: 26528

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 16

Model name: wandb_model_task_1054_seen995K
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_1055_seen9M
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_1058_seen98K
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_1002_seen999M
  Num Parameters: 28365312

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 4
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_1056_seen99M
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 256

Model name: wandb_model_task_1070_seen9M
  Num Parameters: 401024

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 64

Model name: wandb_model_task_1074_seen995K
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 995328

Total batch size: 6,144

Max steps: 162

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_1007_seen999M
  Num Parameters: 26528

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 16

Model name: wandb_model_task_1066_seen99M
  Num Parameters: 26528

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 16

Model name: wandb_model_task_1061_seen99M
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 4
  Embedding size: 768

Model name: wandb_model_task_1078_seen98K
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_1080_seen9M
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_1012_seen999M
  Num Parameters: 401024

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 64

Model name: wandb_model_task_1017_seen999M
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 256

Model name: wandb_model_task_1027_seen999M
  Num Parameters: 26528

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 16

Model name: wandb_model_task_1037_seen999M
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 256

Model name: wandb_model_task_1032_seen999M
  Num Parameters: 401024

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_1077_seen999M
  Num Parameters: 6322688

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 256

Model name: wandb_model_task_1042_seen999M
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 2
  Embedding size: 768

Model name: wandb_model_task_1082_seen999M
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 8
  Embedding size: 768

Model name: wandb_model_task_1022_seen999M
  Num Parameters: 56716800

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 999997440

Total batch size: 6,144

Max steps: 162,760

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 8
  Number of heads: 1
  Embedding size: 768

Model name: wandb_model_task_None_seen98K
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 98304

Total batch size: 6,144

Max steps: 16

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_None_seen9M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: wandb_model_task_None_seen99M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64

Model name: good_val_seen99M
  Num Parameters: 3504

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 16

Model name: bad_val_seen99M
  Num Parameters: 7098624

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 8

GPTConfig parameters:
  Block size: 8
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 768

Model name: original_seen9M
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: original_seen99M
  Num Parameters: 51136

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

Model name: original22_seen99M
  Num Parameters: 101120

File trained on: ../data/2ABT_behavior_run_2.txt

Tokens seen: 99999744

Total batch size: 6,144

Max steps: 16,276

Dataloader parameters:
  Batch size (B): 256
  Sequence length (T): 12

GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 2
  Number of heads: 2
  Embedding size: 64
