I want to test if the transformer can capture a long term dependency within its context length and the control will be a long term dependency outside of its context length

Context length 12

Using the model trained to capture LTDs length 11

===== Pattern-Specific Evaluation (Pattern Length: 11) =====
Overall Accuracy: 0.6970
Pattern Position Accuracy: 0.8777
Non-Pattern Position Accuracy: 0.6789
Pattern Position 'R' Prediction Rate: 0.8777
Pattern Positions containing 'R' in ground truth: 1.0000


Using the model trained to capture LTDs length 15 
**(doesn't make sense becuase it would be outside the context length so
the model can't see the pattern)

===== Pattern-Specific Evaluation (Pattern Length: 11) =====
Overall Accuracy: 0.6621
Pattern Position Accuracy: 0.4480
Non-Pattern Position Accuracy: 0.6835
Pattern Position 'R' Prediction Rate: 0.4480
Pattern Positions containing 'R' in ground truth: 1.0000


Also can't see patterns length 15 because the context length
maxes out at 12
===== Pattern-Specific Evaluation (Pattern Length: 15) =====
Overall Accuracy: 0.6697
Pattern Position Accuracy: 0.4656
Non-Pattern Position Accuracy: 0.6843
Pattern Position 'R' Prediction Rate: 0.4656
Pattern Positions containing 'R' in ground truth: 1.0000


