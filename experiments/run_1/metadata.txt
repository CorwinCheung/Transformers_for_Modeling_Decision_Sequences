Run 1
Dataset tr
Number of steps: 100,000
Multiple contexts: 0
Task parameters:
  B
  Environment parameters:
    {'high_reward_prob': 0.8, 'low_reward_prob': 0.2, 'transition_prob': 0.02}
  Agent parameters:
    {'alpha': 0.75, 'beta': 2.1, 'tau': 1.4, 'policy': 'probability_matching'}

Run 1
Dataset v
Number of steps: 100,000
Multiple contexts: 0
Task parameters:
  B
  Environment parameters:
    {'high_reward_prob': 0.8, 'low_reward_prob': 0.2, 'transition_prob': 0.02}
  Agent parameters:
    {'alpha': 0.75, 'beta': 2.1, 'tau': 1.4, 'policy': 'probability_matching'}


Model name: model_seen9M
  Num Parameters: 51136

Tokens seen: 9996288

Total batch size: 6,144

Max steps: 1,627

Dataloader parameters:

File trained on: /n/home00/cberon/code/Transformers_for_Modeling_Decision_Sequences/experiments/run_1/behavior_run_1tr.txt

File validated on: /n/home00/cberon/code/Transformers_for_Modeling_Decision_Sequences/experiments/run_1/behavior_run_1v.txt
  Batch size (B): 256
  Sequence length (T): 12
  Steps per epoch: 32
GPTConfig parameters:
  Block size: 12
  Vocab size: 4
  Number of layers: 1
  Number of heads: 1
  Embedding size: 64

